{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ERA5_S1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1D94YuL3J-7Mdse8OcjprWAbS8CPVT73q",
      "authorship_tag": "ABX9TyOkM7PeKhM/sNrpeSGMxmPT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cavrinceanu/earthenginescripts/blob/master/ERA5_S1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download matching ERA-5 Hourly Data on single levels from 1979 to present for Sentinel-1 imagery"
      ],
      "metadata": {
        "id": "_Gi1YLd1Ir3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Created by: \n",
        "Cristina Vrinceanu, \n",
        "University of Nottingham, \n",
        "cristina.vrinceanu@nottingham.ac.uk"
      ],
      "metadata": {
        "id": "f6Icm9JPiEBP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iOkcJJFs5R1"
      },
      "source": [
        "This notebook provides the code to couple Sentinel-1 data with ERA-5 daily hourly data from the reanalysis dataset. This has various applications in the marine domain. \n",
        "\n",
        "\n",
        "The code matches Sentinel-1 scene metadata to ERA-5 parameters and downloads 10-m u and v wind vector components in netcdf format for the following parameters: \n",
        "\n",
        "\n",
        "\n",
        "*   Area of interest (scene footprint)\n",
        "*   Hour of acquisition (matching the closest time)\n",
        "*   Date of acquisition (Year, Month, Day)\n",
        "\n",
        "\n",
        "\n",
        "Documentation:   \n",
        "\n",
        "*   [ERA5 hourly data on single levels from 1979 to present](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview)\n",
        "*   [Climate Data Store API](https://cds.climate.copernicus.eu/api-how-to)\n",
        "*   [Sentinel-1 Documentation in GEE](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S1_GRD)\n",
        "*   [Sentinel-1 Mission Documentation ](https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-1)\n",
        "*   [Google Earth Engine Documentation](https://developers.google.com/earth-engine/apidocs/export-table-toasset) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Requirements: Gmail account, Google Earth Engine account, Copernicus Climate Services CDS account, free storage space in Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialise Google Earth Engine and necessary libraries"
      ],
      "metadata": {
        "id": "c3l0toIFNK4S"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBkHVhJH4Kz6"
      },
      "source": [
        "import ee        #GEE library \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import timeit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fckV_5j4UaZ"
      },
      "source": [
        "ee.Authenticate()   #Colab requires authentification to Google. Grant permission and copy/paste the code in the box and hit enter.\n",
        "ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI_MOV8aod1z"
      },
      "source": [
        "Mount personal Google Drive. You can do this operation in the side panel or run the following cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_0wkpMsoIbD"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XURApjHD63SH"
      },
      "source": [
        "## Access the Sentinel-1 product collection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTI6MfGO7H_V"
      },
      "source": [
        "Access the Sentinel-1 data from Google Earth Engine and extract the time of acquisition metadata."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AaebZzxKjUV"
      },
      "source": [
        "#define dates\n",
        "start_date = ee.Date('2018-08-20')\n",
        "end_date = ee.Date('2018-08-31')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd8tLDHT48T9"
      },
      "source": [
        "#define geometrtry from coordinates \n",
        "lat, lng = 41.14, 40.68\n",
        "aoi = ee.Geometry.Point(lat, lng)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHy-RwAW4hD7"
      },
      "source": [
        "#filter Image Collection\n",
        "s1=ee.ImageCollection(\"COPERNICUS/S1_GRD\").filterBounds(aoi).filterDate(start_date, end_date)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcZSlVwnhNjB"
      },
      "source": [
        "#Extract number of Sentinel-1 products\n",
        "count = s1.size()\n",
        "col_count=count.getInfo()\n",
        "print('Count: ', str(col_count)+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3qtgFoONV5O"
      },
      "source": [
        "## Extract metadata and footprints "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgARGfWTnEN8"
      },
      "source": [
        "In this step, we use the geemap library for a quick and interactive visualization. \n",
        "\n",
        "*   Install geemap: https://pypi.org/project/geemap/\n",
        "*   geemap documentation: https://geemap.org/\n",
        "\n",
        "\n",
        "    Wu, Q., (2020). geemap: A Python package for interactive mapping with Google Earth Engine. The Journal of Open Source Software, 5(51), 2305. https://doi.org/10.21105/joss.02305\n",
        "    Wu, Q., Lane, C. R., Li, X., Zhao, K., Zhou, Y., Clinton, N., DeVries, B., Golden, H. E., & Lang, M. W. (2019). Integrating LiDAR data and multi-temporal aerial imagery to map wetland inundation dynamics using Google Earth Engine. Remote Sensing of Environment, 228, 1-13. https://doi.org/10.1016/j.rse.2019.04.015 (pdf | source code)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmlUwAddknMm"
      },
      "source": [
        "#Installation of geemap preferred as following due to some recent library conflicts\n",
        "\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "  import geemap\n",
        "except ImportError:\n",
        "  print ('geemap package not installed. Installing...')\n",
        "  subprocess.check_call([\"python\", '-m', 'pip', 'install', 'geemap'])\n",
        "\n",
        "#alternatively use\n",
        "\n",
        "#pip install geemap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjtpQKczmUIy"
      },
      "source": [
        "import geemap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4Y2duqjyE2c"
      },
      "source": [
        "Get information about which of the metadata is stored in the GEE S-1 product, the structure of the product, details we want to keep, as well as their index name in GEE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzRKaYulvWOi"
      },
      "source": [
        "geemap.image_props(s1.first()).getInfo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define metadata extractor function to extract the metadata (optional)"
      ],
      "metadata": {
        "id": "_8wYW_gUQD7q"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvivJtK-2fg6"
      },
      "source": [
        "#define function to extract data\n",
        "\n",
        "def metadata_extractor(image_collection):\n",
        "\n",
        "  # compute number of images per collection to check the index in ID rows\n",
        "  collection_count=image_collection.size()\n",
        "  print('Count: ', str(collection_count.getInfo())+'\\n')\n",
        "\n",
        "  #obtain metadata from image properties for all images in the collection\n",
        "\n",
        "  image_name =image_collection.aggregate_array('system:index')\n",
        "  image_name= image_name.getInfo()\n",
        "\n",
        "  platform_number = image_collection.aggregate_array('platform_number') \n",
        "  platform_number= platform_number.getInfo()\n",
        "\n",
        "  system_time= image_collection.aggregate_array('system:time_start')\n",
        "  system_time=system_time.getInfo()\n",
        "  system_time= pd.to_datetime(system_time, unit='ms')\n",
        "\n",
        "  segment_time =image_collection.aggregate_array('segmentStartTime')\n",
        "  segment_time=segment_time.getInfo()\n",
        "  segment_time= pd.to_datetime(segment_time, unit='ms')\n",
        "\n",
        "  relative_orbit_start=image_collection.aggregate_array('relativeOrbitNumber_start')\n",
        "  relative_orbit_start=relative_orbit_start.getInfo()\n",
        "\n",
        "  relative_orbit_stop=image_collection.aggregate_array('relativeOrbitNumber_stop')\n",
        "  relative_orbit_stop=relative_orbit_stop.getInfo()\n",
        "\n",
        "  cycle_number = image_collection.aggregate_array('cycleNumber')\n",
        "  cycle_number = cycle_number.getInfo()\n",
        "\n",
        "  slice_number = image_collection.aggregate_array('sliceNumber')\n",
        "  slice_number=slice_number.getInfo()\n",
        "\n",
        "  coordinates = s1.aggregate_array('system:footprint')\n",
        "  coordinates = coordinates.getInfo()\n",
        "\n",
        "\n",
        "  #convert to pandas concatenated dataframe\n",
        "\n",
        "  image_collection_df = pd.DataFrame({'Image_Name': image_name, \n",
        "                                      'Platform_No': platform_number , \n",
        "                                      'System_time': system_time, \n",
        "                                      'Segment_time': segment_time, \n",
        "                                      'RelativeOrbit_start': relative_orbit_start,  \n",
        "                                      'RelativeOrbit_stop': relative_orbit_stop, \n",
        "                                      'Cycle_No': cycle_number, \n",
        "                                      'Slice_No': slice_number,\n",
        "                                      'Coordinates': coordinates})\n",
        "  \n",
        "  return image_collection_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zIgrcNujy_T"
      },
      "source": [
        "#extract data and write it in a csv file\n",
        "s1_meta_csv= metadata_extractor(s1)\n",
        "s1_meta_csv\n",
        "s1_meta_csv.to_csv('/content/drive/MyDrive/GEE_files/s1_metadata_test.csv', index=True, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsuTqUdNjcFm"
      },
      "source": [
        "## Extract Sentinel-1 footprints and get layer extents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJyoWoxVjpsQ"
      },
      "source": [
        "#filter S-1 collection by polarisation (both bands will have the same footprint)\n",
        "vv_collection = s1.select('VV')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eINRx3tmqXCu"
      },
      "source": [
        "#extract first product and create new interactive map and visualise product (optional)\n",
        "vv_image = vv_collection.first()\n",
        "\n",
        "Map = geemap.Map()\n",
        "Map.setCenter(lat, lng, 8)\n",
        "Map.addLayer(vv_image)\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71BTKAykqL7F"
      },
      "source": [
        "#extract footprints from collection metadata\n",
        "\n",
        "def footprints_collection (collection):\n",
        "    footprints_extract = ee.Geometry(collection.get('system:footprint'))\n",
        "    return ee.Feature(collection).copyProperties(collection, collection.propertyNames())\n",
        "\n",
        "\n",
        "footprints = ee.FeatureCollection(vv_collection.map(footprints_collection))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add collection to map (optional)\n",
        "Map.addLayer(footprints)"
      ],
      "metadata": {
        "id": "BtfbeYIWSYHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YfQiesOwkCk"
      },
      "source": [
        "#download footprints to drive as geoJSON. Alternatively, export as Asset \n",
        "\n",
        "export_footprints = ee.batch.Export.table.toDrive(**{\n",
        "    'collection': footprints,\n",
        "    'description': 'footprints_for_images',\n",
        "    'fileFormat': 'GeoJSON',\n",
        "    'folder':'GEE_files'})\n",
        "\n",
        "export_footprints.start()\n",
        "\n",
        "while export_footprints.active():\n",
        "  print('Polling for task (id: {}).'.format(export_footprints.id))\n",
        "\n",
        "print('Finished exporting Image footprints')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct json for CDS API requests"
      ],
      "metadata": {
        "id": "D7AQ-CcmffaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "JSON Format example:\n",
        "\n",
        "{\n",
        "        'product_type': 'reanalysis',\n",
        "        'format': 'netcdf',\n",
        "        'variable': [\n",
        "            '10m_u_component_of_wind', \n",
        "            '10m_v_component_of_wind',\n",
        "        ],\n",
        "        'year': '2021',\n",
        "        'month': '10',\n",
        "        'day': '21',\n",
        "        'time': [\n",
        "            '03:00',\n",
        "        ],\n",
        "        'area': [\n",
        "            43.76, 39.87, 40.49,\n",
        "            41.75,\n",
        "        ],\n",
        "    }"
      ],
      "metadata": {
        "id": "ubIXW5Jef3uj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To manipulate the geometries in a easier fashion, we will use [geopandas](https://geopandas.org/en/stable/) dataframes."
      ],
      "metadata": {
        "id": "vl19FFHva_69"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsHwrt2pL-q6"
      },
      "source": [
        "!pip install geopandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXGxSgA1OT5C"
      },
      "source": [
        "import geopandas as gpd  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bfMY4Vb_8IZ"
      },
      "source": [
        "Construct geodataframe for the exported geojson"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL1uKm1RMsTU"
      },
      "source": [
        "#read geojson file\n",
        "footprints_json= gpd.read_file('/content/drive/MyDrive/GEE_files/footprints_for_images.geojson')\n",
        "footprints_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4GbeJHY8DSy"
      },
      "source": [
        "#extract date, time, geometry attributes - the necessary matching attributes. Alternatively, it can be filtered. \n",
        "\n",
        "footprints_geom = {'id': footprints_json['id'], 'geometry': footprints_json['geometry'], 'timestamp': footprints_json['system:time_start']}\n",
        "\n",
        "#Convert date and time from UNIX format\n",
        "footprints_geom['timestamp'] = pd.to_datetime(footprints_geom['timestamp'], unit='ms')\n",
        "footprints_geom['date'] = [d.date() for d in footprints_geom['timestamp']]\n",
        "footprints_geom['time'] = [t.time() for t in footprints_geom['timestamp']]\n",
        "\n",
        "#construct extents dataframe\n",
        "extent_df= gpd.GeoDataFrame(footprints_geom)\n",
        "extent_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnWWTWW8-myL"
      },
      "source": [
        "#extract geometry bounds: x min, x max, y min, y max\n",
        "bounds= extent_df.bounds\n",
        "bounds\n",
        "# extent_df.total_bounds  //returns the total extent of footprints for larger extent of the area"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSshczzBHFxw"
      },
      "source": [
        "#merge dataframes to add bounds\n",
        "bounds_df = gpd.GeoDataFrame(bounds)\n",
        "key_bounds_df= bounds_df.reset_index()\n",
        "key_extents_df= extent_df.reset_index()\n",
        "final_extents_df= key_extents_df.set_index('index').join(key_bounds_df.set_index('index'))\n",
        "final_extents_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9HVWHzhaIkT"
      },
      "source": [
        "#split date and time \n",
        "final_extents_df['date'] = pd.to_datetime(final_extents_df['date'], format= '%Y-%m-%d')\n",
        "final_extents_df['year'] = pd.DatetimeIndex(final_extents_df['date']).year\n",
        "final_extents_df['month'] = pd.DatetimeIndex(final_extents_df['date']).month\n",
        "final_extents_df['day']= pd.DatetimeIndex(final_extents_df['date']).day\n",
        "final_extents_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map new columns - see json request format in CDS API\n",
        "final_extents_df['area']=final_extents_df.apply(lambda row: [row['maxx'], row['miny'],row['minx'], row['maxy']], axis=1)\n",
        "final_extents_df['product'] = final_extents_df.apply(lambda row: 'reanalysis', axis=1)\n",
        "final_extents_df['format'] = final_extents_df.apply(lambda row: 'netcdf', axis=1)\n",
        "final_extents_df['variables'] = final_extents_df.apply(lambda row: ['10m_u_component_of_wind', '10m_v_component_of_wind'], axis=1)\n",
        "final_extents_df"
      ],
      "metadata": {
        "id": "yWyhG0nCXHdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#round acquistion time to the nearest suitable hour to match model output\n",
        "\n",
        "from datetime import datetime, timedelta, time\n",
        "\n",
        "def rounder(t):\n",
        "    if t.minute >= 30 and t.hour !=23:                       #if minutes past 30 and hour is not 23 then round to next hour. e.g: 15:40:25 -> 16:00:00\n",
        "        return t.replace(second=0, minute=0, hour=t.hour+1)\n",
        "    elif t.minute >= 30 and t.hour >=23:                     #if minutes past 30 and hour is  23 then round to next hour. e.g: 23:40:25 -> 23:00:00\n",
        "        return t.replace(second=0, minute=0, hour=t.hour)\n",
        "    else:\n",
        "        return t.replace(second=0, minute=0, hour=t.hour)    #if minutes not past 30 and hour is not 23 then round to next hour. e.g: 15:20:25 -> 15:00:00\n",
        "\n",
        "#create new time filter\n",
        "for index, row in final_extents_df.iterrows():\n",
        "  print('Current satellite time is:')\n",
        "  print (row[4])\n",
        "  final_extents_df['time_filter'] = final_extents_df.apply(lambda row: rounder(row[4]), axis=1)\n",
        "\n",
        "print(final_extents_df)"
      ],
      "metadata": {
        "id": "5wOgODCbPufd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-Iki1Xfqwn1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get columns index locations for selecting the right index \n",
        "names=final_extents_df.columns.values.tolist()\n",
        "for i in names:\n",
        "  print (final_extents_df.columns.get_loc(i), i)"
      ],
      "metadata": {
        "id": "F22pA52ac3b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#write json in the right format \n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "mkdir = '/content/drive/MyDrive/GEE_files/'\n",
        "\n",
        "def write_json(target_path, target_file, data):\n",
        "    if not os.path.exists(target_path):\n",
        "        try:\n",
        "            os.makedirs(target_path)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            raise\n",
        "    with open(os.path.join(target_path, target_file), 'w') as f:\n",
        "        json.dump(data, f)\n",
        "\n",
        "for index, row in final_extents_df.iterrows():\n",
        "\n",
        "  json_str =  {'product_type': str(row[13]), 'format': str(row[14]), 'variable': (row[15]), 'year': str(row[9]),'month': str(row[10]), 'day': str(row[11]), 'time':[str(row[16])], 'area': (row[12])}\n",
        "  json_i= json.dumps(json_str)\n",
        "  write_json(mkdir, 'download.json', json_i)\n",
        " J\n",
        "  print(json_i)"
      ],
      "metadata": {
        "id": "uWvk9YnGaH_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KEXAb2Z904t"
      },
      "source": [
        "## Accessing the Copernicus Climate Service API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqOR4hNE-ByU"
      },
      "source": [
        "First will be using the Copernicus Data Store API request....\n",
        "https://cds.climate.copernicus.eu/api-how-to \n",
        "\n",
        "To configure, use the following instructions: https://stackoverflow.com/questions/64304862/using-cdsapi-in-google-colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnVsi3-098t1"
      },
      "source": [
        "url = 'url: https://cds.climate.copernicus.eu/api/v2'\n",
        "key = 'key: userkey'\n",
        "\n",
        "with open('/root/.cdsapirc', 'w') as f:\n",
        "    f.write('\\n'.join([url, key]))\n",
        "\n",
        "with open('/root/.cdsapirc') as f:\n",
        "    print(f.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg0zxRvSq8fQ"
      },
      "source": [
        "!pip install cdsapi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAZItmPl-5Pl"
      },
      "source": [
        "import cdsapi\n",
        "c = cdsapi.Client()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmG9b9YB_f0X"
      },
      "source": [
        "#make API request and download data\n",
        "c.retrieve(\n",
        "    'reanalysis-era5-single-levels',\n",
        "    json.loads(json_i),\n",
        "    '/content/drive/MyDrive/GEE_files/download.nc')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}